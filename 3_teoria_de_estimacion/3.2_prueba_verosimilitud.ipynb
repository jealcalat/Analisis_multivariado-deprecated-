{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Teoría de la estimación\n",
    "\n",
    "## 3.2. Prueba de verosimilitud\n",
    "\n",
    "<p align=\"right\">\n",
    "Autor: Emmanuel Alcalá\n",
    "<br>\n",
    "<a href=\"https://scholar.google.com.mx/citations?hl=en&user=3URusCgAAAAJ&view_op=list_works&sortby=pubdate\">Google Scholar</a>\n",
    "</p>\n",
    "\n",
    "<p align=\"left\">\n",
    "<br>\n",
    "<a href=\"https://jealcalat.github.io/Analisis_multivariado/\">Regresar a la página del curso</a>\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumir que la función de densidad o de masa de $X$ es $f(x\\mid \\theta)$ donde $\\theta$ representa uno o más parámetros desconocidos. \n",
    "\n",
    "1. Denotar por $\\Omega$ el espacio total posible para $\\theta$, el conjunto de todos los posibles valores especificados de la hipótesis nula y la alternativa.\n",
    "2. Sea $H_0\\colon \\theta \\in \\omega$ la hipótesis nula, en donde $\\omega$ es un subconjunto de $\\Omega$, el espacio de parámetros.\n",
    "3. Sea $H_a: \\theta \\in \\omega'$ la hipótesis alternativa en donde $\\omega'$ es el complemento de $\\omega$ con respecto a $\\Omega$. Notar que son disjuntos. No pueden ambas hipótesis co-ocurrir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Distribución límite del la razón de verosimilitud\n",
    "\n",
    "Según el teorema de Wilkis\n",
    "\n",
    "Sean $X_1, X_2 \\dots, X_n$ *iid* con función de verosimilitud $L(\\theta)$. Denotamos con $df_0$ el número de parámetros libres especificados por $H_0$ y con $df$ el número de parámetros libres totales (es decir, $\\theta \\in \\Omega$). Entonces, para una $n$ grande, $-2\\log(\\lambda)$ tiene aproximadamente una distribución $\\chi^2$ con grados de libertad $df - df_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo\n",
    "\n",
    "Un ingeniero desea comparar el número de quejas por semana que los representantes de un sindicato de turnos diferentes presentan. 100 observaciones independientes arrojaron $\\bar x = 20$ para el turno de la mañana y $\\bar y=22$ para el turno de la tarde.\n",
    "\n",
    "Suponer que el número de quejas par el i-ésimo turno tiene distribución de Poisson con media $\\theta_i$ para $i=\\{1, 2\\}$. Usar el método de razón de verosimilitud para probar \n",
    "\n",
    "$$\n",
    "  \\begin{align*}\n",
    "    H_0: &\\theta_1=\\theta_2\\quad \\text{vs}\\\\\n",
    "    H_a: &\\theta_1\\neq\\theta_2\\quad \\text{para } \\alpha = 0.01\n",
    "  \\end{align*}\n",
    "$$\n",
    "\n",
    "Solución\n",
    "\n",
    "La razón de verosimilitud está dada por\n",
    "\n",
    "$$\n",
    "  \\lambda = \\frac{L(\\hat\\omega)}{L(\\hat\\Omega)}\n",
    "$$\n",
    "En este ejemplo $\\Omega=(\\theta_1,\\theta_2)$ y $\\omega=\\{(\\theta_1,\\theta_2)\\colon\\theta_1=\\theta_2=\\theta\\}$\n",
    "\n",
    "Por lo tanto, $L(\\Omega)=L(\\theta_1,\\theta_2)=L(\\theta_1)\\times L(\\theta_2)$ porque $L(\\cdot)$ es multiplicativa debido a que son independientes.\n",
    "\n",
    "$$\n",
    "  L(\\theta_1,\\theta_2)=\\frac{1}{\\prod X_i!}\\frac{1}{\\prod Y_i!}\\theta_1^{\\sum X_i}e^{-n\\theta_1}\\theta_2^{\\sum Y_i}e^{-n\\theta_2}\n",
    "$$\n",
    "\n",
    "Notar que, bajo la nula, $\\theta_1=\\theta_2=\\theta$, es decir, se asume que $X_i, Y_i\\sim \\text{Poisson}(\\theta)$ por lo que\n",
    "\n",
    "$$\n",
    "  L(\\theta)=\\frac{1}{\\prod X_i!}\\frac{1}{\\prod Y_i!}\\theta^{\\sum X_i+\\sum Y_i}e^{-2n\\theta}\n",
    "$$\n",
    "\n",
    "También, habíamos visto que el MLE para Poisson era\n",
    "\n",
    "$$\n",
    "  \\hat\\theta=\\frac{1}{n}\\sum_{i=1}^n X_i\n",
    "$$\n",
    "\n",
    "Pero en este caso, bajo la nula\n",
    "\n",
    "$$\n",
    "  \\hat\\theta=\\frac{1}{2n}\\left(\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i \\right)=\\frac{1}{2}(\\bar x + \\bar y)\n",
    "$$\n",
    "\n",
    "¿Y para $L(\\theta_1, \\theta_2)$?\n",
    "Resolver en clase.\n",
    "\n",
    "---\n",
    "\n",
    "Respuesta\n",
    "\n",
    "Descartando términos que no dependen de $\\theta_1,\\theta_2$\n",
    "\n",
    "$$\n",
    "  L(\\theta_1,\\theta_2)=\\theta_1^{\\sum X_i}e^{-n\\theta_1}\\theta_2^{\\sum Y_i}e^{-n\\theta_2}\n",
    "$$\n",
    "\n",
    "Log-transformando\n",
    "\n",
    "$$\n",
    "  l(\\theta_1,\\theta_2)=\\log \\left( \\theta_1^{\\sum X_i}e^{-n\\theta_1}\\theta_2^{\\sum Y_i}e^{-n\\theta_2} \\right)=-n\\theta_1-n\\theta_2 +\\sum X_i\\log(\\theta_1)+\\sum Y_i\\log(\\theta_2)\n",
    "$$\n",
    "\n",
    "Diferenciando, primero con respecto a $\\theta_1$ y luego con respecto a $\\theta_2$\n",
    "\n",
    "$$\n",
    "    l'(\\theta_1,\\theta_2)\\Big|_{\\theta_2}=-n + \\frac{\\sum X_i}{\\theta_1}=0\\Longrightarrow \\theta_1=\\frac{1}{n}X_i=\\bar x\n",
    "$$\n",
    "\n",
    "$$\n",
    "    l'(\\theta_1,\\theta_2)\\Big|_{\\theta_1}=-n + \\frac{\\sum X_i}{\\theta_2}=0\\Longrightarrow \\theta_2=\\frac{1}{n}Y_i=\\bar y\n",
    "$$\n",
    "\n",
    "Ahora ya podemos sustituir $\\bar x, \\bar y$ y $\\hat \\theta$ en $\\lambda$\n",
    "\n",
    "$$\n",
    "  \\lambda = \\frac{L(\\hat\\omega)}{L(\\hat\\Omega)}=\\frac{\\hat \\theta^{\\sum X_i+\\sum Y_i e^{-2n\\hat \\theta}}}{\\hat\\theta_1^{\\sum X_i}}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
